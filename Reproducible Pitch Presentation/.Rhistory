library(slidify)
install_github('slidify','ramnathv')
install_github('slidifyLibraries','ramnathv')
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
head(concrete)
plot(mixtures$CompressiveStrength)
plot(mixtures$CompressiveStrength,data=training)
qplot(mixtures$CompressiveStrength,data=training)
library(ggplot2)
qplot(mixtures$CompressiveStrength,data=training)
names <- colnames(concrete)
names
names <- names[-length(names)]
names
names <- colnames(concrete)
names
names <- names[-CompressiveStrength]
names <- names[-"CompressiveStrength"]
names <- names[-c("CompressiveStrength")]
names <- names[-c(CompressiveStrength)]
names <- names[-9]
names
featurePlot(x = training[, names], y = training$CompressiveStrength, plot = "pairs")
index <- seq_along(1:nrow(training))
ggplot(data = training, aes(x = index, y = CompressiveStrength)) + geom_point() +
theme_bw()
cutCS <- cut2(training$CompressiveStrength, g = 4)
summary(cutCS)
ggplot(data = training, aes(y = index, x = cutCS)) + geom_boxplot() + geom_jitter(col = "blue") +
theme_bw()
library(Hmisc)
cutCS <- cut2(training$CompressiveStrength, g = 4)
summary(cutCS)
ggplot(data = training, aes(y = index, x = cutCS)) + geom_boxplot() + geom_jitter(col = "blue") +
theme_bw()
featurePlot(x = training[, names], y = cutCS, plot = "box")
ggplot(data = training, aes(x = Superplasticizer)) + geom_histogram() + theme_bw()
IL_str <- grep("^IL", colnames(training), value = TRUE)
preProc <- preProcess(training[, IL_str], method = "pca", thresh = 0.8)
preProc$rotation
IL_str
colnames(training)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
IL_str <- grep("^IL", colnames(training), value = TRUE)
preProc <- preProcess(training[, IL_str], method = "pca", thresh = 0.8)
preProc$rotation
predictors
head(predictors)
IL_str <- grep("^IL", colnames(training), value = TRUE)
predictors_IL <- predictors[, IL_str]
df <- data.frame(diagnosis, predictors_IL)
inTrain = createDataPartition(df$diagnosis, p = 3/4)[[1]]
training = df[inTrain, ]
testing = df[-inTrain, ]
modelFit <- train(diagnosis ~ ., method = "glm", data = training)
predictions <- predict(modelFit, newdata = testing)
C1 <- confusionMatrix(predictions, testing$diagnosis)
print(C1)
library(caret)
modelFit <- train(diagnosis ~ ., method = "glm", data = training)
predictions <- predict(modelFit, newdata = testing)
C1 <- confusionMatrix(predictions, testing$diagnosis)
print(C1)
install.packages("e1071")
modelFit <- train(diagnosis ~ ., method = "glm", data = training)
predictions <- predict(modelFit, newdata = testing)
C1 <- confusionMatrix(predictions, testing$diagnosis)
print(C1)
modelFit2 <- train(training$diagnosis ~ ., method = "glm", preProcess = "pca",
data = training, trControl = trainControl(preProcOptions = list(thresh = 0.8)))
C2 <- confusionMatrix(testing$diagnosis, predict(modelFit2, testing))
print(C2)
modelFit1 <- train(diagnosis ~ ., method = "glm", data = training)
predictions <- predict(modelFit1, newdata = testing)
C1 <- confusionMatrix(predictions, testing$diagnosis)
print(C1)
modelFit2 <- train(training$diagnosis ~ ., method = "glm", preProcess = "pca",
data = training, trControl = trainControl(preProcOptions = list(thresh = 0.8)))
C2 <- confusionMatrix(testing$diagnosis, predict(modelFit2, testing))
print(C2)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
IL_str <- grep("^IL", colnames(training), value = TRUE)
predictors_IL <- predictors[, IL_str]
df <- data.frame(diagnosis, predictors_IL)
inTrain = createDataPartition(df$diagnosis, p = 3/4)[[1]]
training = df[inTrain, ]
testing = df[-inTrain, ]
modelFit1 <- train(diagnosis ~ ., method = "glm", data = training)
predictions <- predict(modelFit1, newdata = testing)
C1 <- confusionMatrix(predictions, testing$diagnosis)
print(C1)
modelFit2 <- train(training$diagnosis ~ ., method = "glm", preProcess = "pca",
data = training, trControl = trainControl(preProcOptions = list(thresh = 0.8)))
C2 <- confusionMatrix(testing$diagnosis, predict(modelFit2, testing))
print(C2)
library(caret)
library(AppliedPredictiveModeling
)
set.seed(3433)
data(AlzheimerDisease)
diagnosis
IL_str <- grep("^IL", colnames(training), value = TRUE)
predictors_IL <- predictors[, IL_str]
df <- data.frame(diagnosis, predictors_IL)
inTrain = createDataPartition(df$diagnosis, p = 3/4)[[1]]
training = df[inTrain, ]
testing = df[-inTrain, ]
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
IL_str <- grep("^IL", colnames(training), value = TRUE)
predictors_IL <- predictors[, IL_str]
df <- data.frame(diagnosis, predictors_IL)
inTrain = createDataPartition(df$diagnosis, p = 3/4)[[1]]
training = df[inTrain, ]
testing = df[-inTrain, ]
modelFit1 <- train(diagnosis ~ ., method = "glm", data = training)
predictions <- predict(modelFit1, newdata = testing)
C1 <- confusionMatrix(predictions, testing$diagnosis)
C1
modelFit2 <- train(training$diagnosis ~ ., method = "glm", preProcess = "pca",
data = training, trControl = trainControl(preProcOptions = list(thresh = 0.8)))
C2 <- confusionMatrix(testing$diagnosis, predict(modelFit2, testing))
C2
sample(1:10)
sample(1:10,replace=T)
install.packages("ElemStatLearn")
data(ozone)
library(ElemStatLearn)
data(ozone)
dim(ozone)
head(ozone)
sample(1:dim(ozone),replace=T)
sample(1:dim(ozone)[1],replace=T)
summary(ozone$ozone)
ll<-matrix(NA,nrow=10,ncol=155)
i=1
ss<-sample(1:dim(ozone)[1],replace=T)
ozone0<-ozone[ss,]
ozone0<-ozone0[order(ozone0$ozone),]
loess0<-loess(temperature~ozone,data=ozone0,span=0.2)
loess0
?apply
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
head(segmentationOriginal)
colnames(segmentationOriginal)
?createDataPartition
inTrain<-createDataPartition(y=segmentationOriginal$Case)
training<-segmentationOriginal[inTrain,]
testing<-segmentationOriginal[-inTrain,]
inTrain<-createDataPartition(y=segmentationOriginal$Case,list=F)
training<-segmentationOriginal[inTrain,]
testing<-segmentationOriginal[-inTrain,]
modFit<-train(Case~.,method="rpart",data=training)
test<-data.frame(TotalIntench2 = 23,000, FiberWidthCh1 = 10; PerimStatusCh1=2)
test<-data.frame(TotalIntench2 = 23000, FiberWidthCh1 = 10, PerimStatusCh1=2)
test
test<-data.frame(TotalIntench2 = 23000,FiberWidthCh1 = 10,PerimStatusCh1=2,
TotalIntench2 = 50000,FiberWidthCh1 = 10,VarIntenCh4 = 100,
TotalIntench2 = 57000,FiberWidthCh1 = 8,VarIntenCh4 = 100,
FiberWidthCh1 = 8,VarIntenCh4 = 100,PerimStatusCh1=2,
nrow=4,ncol=3 )
test
?data.frame
test<-matrix(TotalIntench2 = 23000,FiberWidthCh1 = 10,PerimStatusCh1=2,
TotalIntench2 = 50000,FiberWidthCh1 = 10,VarIntenCh4 = 100,
TotalIntench2 = 57000,FiberWidthCh1 = 8,VarIntenCh4 = 100,
FiberWidthCh1 = 8,VarIntenCh4 = 100,PerimStatusCh1=2,
nrow=4,ncol=3 )
test1<-data.frame(TotalIntench2 = 23000,FiberWidthCh1 = 10,PerimStatusCh1=2)
predict(modFit,newdata=test1)
modFit<-train(Class~.,method="rpart",data=training)
test1<-data.frame(TotalIntench2 = 23000,FiberWidthCh1 = 10,PerimStatusCh1=2)
predict(modFit,newdata=test1)
print(modFit$finalModel)
library(rattle)
install.packages("rattle")
library(rattle)
fancyRpartPlot(modFit$finalModel)
install.packages("rpart.plot")
fancyRpartPlot(modFit$finalModel)
library(pgmm)
install.packages("pgmm")
library(pgmm)
data(olive)
olive = olive[,-1]
modFit<-train(Area~.,method="rpart",data=olive)
predict(modFit,newdata)
newdata = as.data.frame(t(colMeans(olive)))
predict(modFit,newdata)
install.packages("tree")
?tree
?tree()
??tree
?tree
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
colnames(SAheart)
modFit<-glm(chd~age+alcohol+obesity+tobacco+typea+ldl,data=SAheart,family="binomial")
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
prediction1<-(modFit,trainSA)
prediction2<-(modFit,testSA)
prediction1<-(modFit, trainSA)
prediction1<-predict(modFit,trainSA)
prediction2<-predict(modFit,testSA)
missClass1<-missClass(trainSA,prediction1)
missClass2<-missClass(testSA,prediction2)
missClass1
missClass2
dim(trainSA)
trainSA<-as.vector(trainSA)
testSA<-as.vector(testSA)
prediction1<-predict(modFit,trainSA)
prediction2<-predict(modFit,testSA)
missClass1<-missClass(trainSA,prediction1)
missClass2<-missClass(testSA,prediction2)
missClass1
dim(trainSA)
trainSA<-as.vector(trainSA)
trainSA
head(trainSA)
dim(prediction1)
len(prediction1)
length(prediction1)
head(trainSA[,10])
missClass1<-missClass(trainSA[,10],prediction1)
missClass2<-missClass(testSA[,10],prediction2)
missClass1
missClass2
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
modFit<-glm(chd~age+alcohol+obesity+tobacco+typea+ldl,data=SAheart,family="binomial")
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
prediction1<-predict(modFit,trainSA)
prediction2<-predict(modFit,testSA)
missClass1<-missClass(trainSA[,10],prediction1)
missClass2<-missClass(testSA[,10],prediction2)
missClass1
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
set.seed(33833)
training<-data(vowel.train)
testing<-data(vowel.test)
head(training)
vowel.train
training
training<-vowel.train
testing<-vowel.test
head(training)
modFit<-train(y~.,data=training,method="rf",prox=T)
modFit<-train(y~.,data=training,method="rf",prox=T,importance=T)
modFit$finalModel$importance
varImp(modFit$finalModel,type=2)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
training<-vowel.train
testing<-vowel.test
y<-factor(y)
y<-factor(vowel.train$y)
y
summary(vowel.train$y)
vowel.train$y<-factor(vowel.train$y)
vowel.train$y
set.seed(33833)
modFit<-train(y~.,data=training,method="rf",prox=T,importance=T)
modFit$finalModel$importance
varImp(modFit$finalModel,type=2)
vowel.train$y<-factor(vowel.train$y)
vowel.test$y<-factor(vowel.test$y)
vowel.train$y
vowel.test$y
modFit<-train(y~.,data=training,method="rf",importance=T)
modFit$finalModel$importance
varImp(modFit$finalModel,type=2)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
inTrain<-createDataPartition(y=segmentationOriginal$Case,list=F)
training<-segmentationOriginal[inTrain,]
set.seed(125)
modFit<-train(Class~.,method="rpart",data=training)
test1<-data.frame(TotalIntench2 = 23000,FiberWidthCh1 = 10,PerimStatusCh1=2)
library(rattle)
fancyRpartPlot(modFit$finalModel)
colnames(segmentationOriginal)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
inTrain<-createDataPartition(y=segmentationOriginal$Case,list=F)
training<-segmentationOriginal[inTrain,]
set.seed(125)
modFit<-train(Class~.,method="rpart",data=training)
library(rattle)
fancyRpartPlot(modFit$finalModel)
modFit$finalModel
data(mtcars)
str(mtcars)
mtcars$cyl <- factor(mtcars$cyl)
mtcars$vs <- factor(mtcars$vs)
mtcars$gear <- factor(mtcars$gear)
mtcars$carb <- factor(mtcars$carb)
mtcars$am <- factor(mtcars$am,labels=c('Automatic','Manual'))
t.test(mpg ~ am, data = mtcars)
wilcox.test(mpg ~ am, data = mtcars)
mod_init <- lm(mpg ~ ., data = mtcars)
mod_best <- step(mod_init, direction = "both")
summary(mod_best)
mod_base <- lm(mpg ~ am, data = mtcars)
anova(mod_best, mod_base)
leverage <- hatvalues(mod_best)
leverage[which(leverage > 0.5)]
leverage <- hatvalues(mod_best)
tail(sort(leverage),3)
sort(leverage)
influential <- dfbetas(mod_best)
tail(sort(influential),3)
summary(mod_best)
plot(mpg ~ am, data = mtcars, main = "Mpg by transmission type", xlab = "Transmission type", ylab = "Miles per gallon")
pairs(mtcars, panel = panel.smooth, main = "Pairs graph for MTCars")
par(mfrow = c(2, 2))
plot(fitted(mod_best), residuals(mod_best), xlab = "Fitted values", ylab = "Residuals", main = "Residuals vs Fitted")
abline(h = 0, col = "red")
qqnorm(residuals(mod_best))
qqline(residuals(mod_best), col = "red")
plot(fitted(mod_best), sqrt(abs(rstandard(mod_best))), xlab = "Fitted values", ylab = "Square Root of Standardized Residuals", main = "Scale-Location")
getwd()
library(caret)
set.seed(1234)
?read.csv
?apply
x <- cbind(x1 = 3, x2 = c(4:1, 2:5))
x
col.sums <- apply(x, 2, sum)
col.sums
rawData <- read.csv("pml-training.csv", na.strings=c("NA",""), strip.white=T)
dim(rawData)
na <- apply(rawData, 2, function(x) { sum(is.na(x)) })
cleandata <- subset(rawData[, which(na == 0)], select=-c(X, user_name, new_window, num_window, raw_timestamp_part_1, raw_timestamp_part_2, cvtd_timestamp))
dim(cleandata)
rawData <- read.csv("pml-training.csv", na.strings=c("NA",""), strip.white=T)
Totalna <- apply(rawData, 2, function(x) { sum(is.na(x)) })
cleandata <- subset(rawData[, which(Totalna == 0)], select=-c(X, user_name, new_window, num_window, raw_timestamp_part_1, raw_timestamp_part_2, cvtd_timestamp))
inTrain <- createDataPartition(cleandata$classe, p=0.7, list=F)
training <- cleandata[inTrain,]
testing <- cleandata[-inTrain,]
?plotcp
??plotcp
#Fitting the Model
modFit<-train(classe~.,data=training,method="rpart")
#Visualizing the Model Results
library(rattle)
fancyRpartPlot(modFit$finalModel)
predictions<-predict(modFit,newdata=testing)
confusionMatrix(predictions,testing$classe)
#Fitting the Model
modFit<-train(classe~.,data=training,method="rf",prox=T)
rawData <- read.csv("pml-training.csv", na.strings=c("NA",""), strip.white=T)
Totalna <- apply(rawData, 2, function(x) { sum(is.na(x)) })
cleandata <- subset(rawData[, which(Totalna == 0)], select=c(roll_belt, pitch_forearm, yaw_belt, magnet_dumbbell_y, pitch_belt, magnet_dumbbell_z, roll_forearm, accel_dumbbell_y, roll_dumbbell, magnet_dumbbell_x,classe))
inTrain <- createDataPartition(cleandata$classe, p=0.7, list=F)
training <- cleandata[inTrain,]
testing <- cleandata[-inTrain,]
#Fitting the Model
ctrl <- trainControl(allowParallel=T, method="cv", number=4)
modFit<-train(classe~.,data=training,method="rf",trControl=ctrl)
#Visualizing the Model Results
modFit
predictions<-predict(modFit,newdata=testing)
confusionMatrix(predictions,testing$classe)
rawdata2 <- read.csv("pml-testing.csv", na.strings=c("NA",""), strip.white=T)
testdata <- subset(rawdata2[, which(na == 0)], select=c(roll_belt, pitch_forearm, yaw_belt, magnet_dumbbell_y, pitch_belt, magnet_dumbbell_z, roll_forearm, accel_dumbbell_y, roll_dumbbell, magnet_dumbbell_x,classe))
predictions2 <- predict(modFit, newdata=testdata)
confusionMatrix(testdata$classe, predictions2)
rawdata2 <- read.csv("pml-testing.csv", na.strings=c("NA",""), strip.white=T)
predictions2 <- predict(modFit, newdata=rawdata2)
predictions2
runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
library(devtools)
library(slidify)
setwd("~/Reproducible Pitch Presentation")
author("Reproducible Pitch Presentation")
summary(faithful)
library(manipulate)
myHist <- function(mu){
hist(galton$child,col="blue",breaks=100)
lines(c(mu, mu), c(0, 150),col="red",lwd=5)
mse <- mean((galton$child - mu)^2)
text(63, 150, paste("mu = ", mu))
text(63, 140, paste("MSE = ", round(mse, 2)))
}
manipulate(myHist(mu), mu = slider(62, 74, step = 0.5))
data(galton)
library(manipulate)
myHist <- function(mu){
hist(galton$child,col="blue",breaks=100)
lines(c(mu, mu), c(0, 150),col="red",lwd=5)
mse <- mean((galton$child - mu)^2)
text(63, 150, paste("mu = ", mu))
text(63, 140, paste("MSE = ", round(mse, 2)))
}
manipulate(myHist(mu), mu = slider(62, 74, step = 0.5))
library(manipulate)
myHist <- function(mu){
hist(faithful[,2],col="blue",breaks=100)
lines(c(mu, mu), c(0, 150),col="red",lwd=5)
mse <- mean((faithful[,2] - mu)^2)
text(63, 150, paste("mu = ", mu))
text(63, 140, paste("MSE = ", round(mse, 2)))
}
manipulate(myHist(mu), mu = slider(62, 74, step = 0.5))
library(manipulate)
myHist <- function(mu){
hist(faithful[,2],col="blue",breaks=100)
lines(c(mu, mu), c(0, 150),col="red",lwd=5)
mse <- mean((faithful[,2] - mu)^2)
text(63, 150, paste("mu = ", mu))
text(63, 140, paste("MSE = ", round(mse, 2)))
}
manipulate(myHist(mu), mu = slider(62, 74, step = 0.5))
library(manipulate)
num=10
myHist <- function(num){
hist(faithful[,2],col="blue",breaks=num)
}
manipulate(myHist(num), mu = slider(1, 100, step = 5))
library(manipulate)
num=10
myHist <- function(num){
hist(faithful[,2],col="blue",breaks=num)
}
manipulate(myHist(num), num = slider(1, 100, step = 5))
library(manipulate)
myHist <- function(num){
hist(faithful[,2],col="blue",breaks=num)
}
manipulate(myHist(num), num = slider(1, 100, step = 5))
shiny::runApp('~')
myHist <- function(color){
hist(faithful[,2],col=color,breaks=10)
}
manipulate(myHist(color), color = slider(1, 8, step = 1))
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
